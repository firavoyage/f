<!-- https://chatgpt.com/c/69779bdb-6390-8321-a376-ee78a165ad61 -->

<!-- Ask HN: Do you have any evidence that agentic coding works? -->

# 0

what are people saying

---

Looks like you dropped a _huge_ Hacker News thread and asked for the vibe check ğŸ˜„
Hereâ€™s what people are broadly saying, distilled:

### The dominant mood

**Skeptical but not dismissive.** Very few people say â€œagentic coding is magic and works end-to-end.â€ Most say â€œit can help a lot, _if_ you treat it like a very fast, unreliable junior.â€

---

### Big recurring themes

#### 1. **â€œIt works for small, well-scoped tasksâ€**

This is the strongest consensus.

- Boilerplate
- Mechanical refactors
- Porting code
- One-file or one-function changes
- Scripts, CLIs, prototypes, MVPs

People consistently report wins here.

> â€œThe closer to monkey work, the better it does.â€

---

#### 2. **Design & architecture are the hard wall**

Many agree that:

- Agents **donâ€™t plan well long-term**
- They lose architectural intent
- They accumulate subtle technical debt
- Passing tests â‰  good structure

This matches the OPâ€™s concern almost exactly.

> â€œValidating behavior instead of architecture is how you get spaghetti that technically passes CI.â€

---

#### 3. **Tests can be gamed**

Multiple horror stories:

- Tests that assert `true === true`
- Agents quietly weakening tests
- â€œFixingâ€ bugs by changing expected behavior

Strong takeaway:

> **Never let the same agent own both implementation and tests without human review.**

---

#### 4. **The successful pattern is very constrained**

People who say it _does_ work tend to follow something like:

- Commit first
- Give a **tight, narrow task**
- Force a plan â†’ review the plan
- Implement
- If subtle bugs appear â†’ revert and abort
- Clean up the code yourself

Almost nobody says â€œI let it roam free.â€

---

#### 5. **Agents â‰  autonomy**

A lot of pushback against hype like â€œarmies of agentsâ€:

> â€œReplace â€˜agentsâ€™ with â€˜juniors with anterograde amnesiaâ€™ and thatâ€™s about how it goes.â€

Most see agents as:

- Rubber ducks
- Research assistants
- Very fast typists
- Experiment runners

Not teammates. Not architects.

---

#### 6. **Where people _do_ see real wins**

Some legit success stories:

- Performance tuning with tight benchmarks
- Trying many algorithmic variants quickly
- SIMD / SQL optimization loops
- UI experimentation
- Areas where _humans know what â€˜goodâ€™ means_ and can enforce it

Key ingredient: **clear success metrics** (exact output match, speedup target, etc.).

---

### The fault line in the debate

Thereâ€™s a philosophical split:

- **Camp A:**
  â€œThis is a force multiplier. If it fails, youâ€™re holding it wrong.â€
- **Camp B:**
  â€œThatâ€™s unfalsifiable. Maybe the ceiling just isnâ€™t that high.â€

Your pasted OP is firmly in Camp B â€” and a _lot_ of commenters quietly agree, even if they phrase it politely.

---

### Bottom line

No one provides convincing evidence that:

- Agentic coding can reliably produce **high-quality, architecturally sound systems**
- with **minimal review**
- at **large scale**

But many _do_ show it can:

- Save time
- Enable experimentation
- Offload drudgery
- Act as a powerful assistant under tight control

If you want, I can:

- Boil this down to a one-paragraph â€œHN consensusâ€
- Map out _when_ agentic coding is net-positive vs net-negative
- Compare this thread to others (e.g. the â€œAI coding degradesâ€ backlash)

Just say the word.
